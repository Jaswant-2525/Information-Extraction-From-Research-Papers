{
  "tokens_with_labels": [],
  "named_entities": [
    [
      "IR",
      "ORG"
    ],
    [
      "30 Jan 2024",
      "DATE"
    ],
    [
      "Yangyang Liu1[0009−0001−0539−338X",
      "PERSON"
    ],
    [
      "New Zealand",
      "GPE"
    ],
    [
      "2 Institute of Software Chinese Academy of Sciences",
      "ORG"
    ],
    [
      "Beijing",
      "GPE"
    ],
    [
      "China",
      "GPE"
    ],
    [
      "scientiﬁc research",
      "ORG"
    ],
    [
      "PDF",
      "ORG"
    ],
    [
      "AutoIE",
      "GPE"
    ],
    [
      "four",
      "CARDINAL"
    ],
    [
      "1",
      "CARDINAL"
    ],
    [
      "PDF",
      "ORG"
    ],
    [
      "2",
      "CARDINAL"
    ],
    [
      "3",
      "CARDINAL"
    ],
    [
      "4",
      "CARDINAL"
    ],
    [
      "SBERT",
      "PERSON"
    ],
    [
      "Marco F1",
      "ORG"
    ],
    [
      "87.19",
      "CARDINAL"
    ],
    [
      "89.65",
      "CARDINAL"
    ],
    [
      "ADE",
      "ORG"
    ],
    [
      "AutoIE",
      "GPE"
    ],
    [
      "78%",
      "PERCENT"
    ],
    [
      "scientiﬁc docu-\nment",
      "PERSON"
    ],
    [
      "Analysis",
      "ORG"
    ],
    [
      "1",
      "CARDINAL"
    ],
    [
      "an approximate 4%",
      "PERCENT"
    ],
    [
      "annual",
      "DATE"
    ],
    [
      "1",
      "CARDINAL"
    ],
    [
      "AutoIE",
      "GPE"
    ],
    [
      "2",
      "CARDINAL"
    ],
    [
      "Yangyang Liu",
      "PERSON"
    ],
    [
      "Shoubin Li",
      "PERSON"
    ],
    [
      "1",
      "CARDINAL"
    ],
    [
      "2",
      "CARDINAL"
    ],
    [
      "3",
      "CARDINAL"
    ],
    [
      "Fig",
      "PERSON"
    ],
    [
      "1",
      "CARDINAL"
    ],
    [
      "three",
      "CARDINAL"
    ],
    [
      "Location Unit, Information Extraction Unit",
      "ORG"
    ],
    [
      "Display and Human Feedback\nUnit",
      "ORG"
    ],
    [
      "Location Unit",
      "ORG"
    ],
    [
      "the Multi-Semantic Feature\nFusion",
      "ORG"
    ],
    [
      "Approach",
      "ORG"
    ],
    [
      "PDF Document Layout Analysis",
      "ORG"
    ],
    [
      "Advanced Functional Block Recognition",
      "ORG"
    ],
    [
      "Scientiﬁc Texts",
      "PERSON"
    ],
    [
      "AFBRSC",
      "ORG"
    ],
    [
      "the Information Extraction Unit",
      "ORG"
    ],
    [
      "SBERT",
      "PERSON"
    ],
    [
      "the Human Feedback Unit",
      "ORG"
    ],
    [
      "the Online Learning Paradigm Tailored\nMethod",
      "ORG"
    ],
    [
      "OLPTM",
      "ORG"
    ],
    [
      "1",
      "CARDINAL"
    ],
    [
      "SBERT’s Technical Superiority",
      "ORG"
    ],
    [
      "SBERT",
      "PERSON"
    ],
    [
      "Marco F1",
      "FAC"
    ],
    [
      "87.19",
      "CARDINAL"
    ],
    [
      "89.65",
      "CARDINAL"
    ],
    [
      "ADE",
      "ORG"
    ],
    [
      "78%",
      "PERCENT"
    ],
    [
      "SBERT",
      "ORG"
    ],
    [
      "2",
      "CARDINAL"
    ],
    [
      "AutoIE",
      "GPE"
    ],
    [
      "AutoIE",
      "GPE"
    ],
    [
      "Molecular",
      "GPE"
    ],
    [
      "3",
      "CARDINAL"
    ],
    [
      "2.1",
      "CARDINAL"
    ],
    [
      "16",
      "CARDINAL"
    ],
    [
      "SSD",
      "ORG"
    ],
    [
      "17",
      "CARDINAL"
    ],
    [
      "YOLO",
      "ORG"
    ],
    [
      "18",
      "CARDINAL"
    ],
    [
      "2017",
      "DATE"
    ],
    [
      "19",
      "CARDINAL"
    ],
    [
      "2.2",
      "CARDINAL"
    ],
    [
      "Bowen",
      "PERSON"
    ],
    [
      "al",
      "PERSON"
    ],
    [
      "21",
      "CARDINAL"
    ],
    [
      "Zeng",
      "PERSON"
    ],
    [
      "al",
      "PERSON"
    ],
    [
      "22",
      "CARDINAL"
    ],
    [
      "6",
      "CARDINAL"
    ],
    [
      "23",
      "CARDINAL"
    ],
    [
      "6",
      "CARDINAL"
    ],
    [
      "BERT",
      "ORG"
    ],
    [
      "BERT",
      "ORG"
    ],
    [
      "Fatema et al",
      "PERSON"
    ],
    [
      "24",
      "CARDINAL"
    ],
    [
      "Bert",
      "PERSON"
    ],
    [
      "NLP",
      "ORG"
    ],
    [
      "BERT",
      "ORG"
    ],
    [
      "SBERT",
      "PERSON"
    ],
    [
      "BERT",
      "ORG"
    ],
    [
      "3",
      "CARDINAL"
    ],
    [
      "Fig",
      "PERSON"
    ],
    [
      "1",
      "CARDINAL"
    ],
    [
      "4",
      "CARDINAL"
    ],
    [
      "Yangyang Liu",
      "PERSON"
    ],
    [
      "Shoubin Li",
      "PERSON"
    ],
    [
      "Location",
      "ORG"
    ],
    [
      "1",
      "CARDINAL"
    ],
    [
      "3.1",
      "CARDINAL"
    ],
    [
      "3.1.1",
      "CARDINAL"
    ],
    [
      "Location",
      "ORG"
    ],
    [
      "Location Unit",
      "ORG"
    ],
    [
      "PDF",
      "ORG"
    ],
    [
      "two",
      "CARDINAL"
    ],
    [
      "PDF",
      "ORG"
    ],
    [
      "Firstly",
      "ORDINAL"
    ],
    [
      "2",
      "CARDINAL"
    ],
    [
      "PDF",
      "ORG"
    ],
    [
      "3",
      "CARDINAL"
    ],
    [
      "3.1.2 Information Extraction",
      "ORG"
    ],
    [
      "The Information Extraction Unit",
      "ORG"
    ],
    [
      "Layout",
      "GPE"
    ],
    [
      "Human Feedback Unit",
      "ORG"
    ],
    [
      "Title Suppressed Due to Excessive Length",
      "WORK_OF_ART"
    ],
    [
      "5",
      "CARDINAL"
    ],
    [
      "Sentence-BERT",
      "ORG"
    ],
    [
      "SBERT",
      "ORG"
    ],
    [
      "3.1.3",
      "CARDINAL"
    ],
    [
      "Display and Human Feedback Unit",
      "ORG"
    ],
    [
      "The Display and Human Feedback Unit",
      "ORG"
    ],
    [
      "SBERT",
      "PERSON"
    ],
    [
      "the Information Extraction",
      "ORG"
    ],
    [
      "Model Training Units",
      "PERSON"
    ],
    [
      "3.2",
      "CARDINAL"
    ],
    [
      "SBERT",
      "PERSON"
    ],
    [
      "PDF",
      "ORG"
    ],
    [
      "3.2.1",
      "CARDINAL"
    ],
    [
      "Span Embedding",
      "PERSON"
    ],
    [
      "4",
      "CARDINAL"
    ],
    [
      "BERT",
      "ORG"
    ],
    [
      "Width Embedding",
      "PERSON"
    ],
    [
      "5",
      "CARDINAL"
    ],
    [
      "6",
      "CARDINAL"
    ],
    [
      "BERT",
      "ORG"
    ],
    [
      "7",
      "CARDINAL"
    ],
    [
      "NLTK",
      "ORG"
    ],
    [
      "8",
      "CARDINAL"
    ],
    [
      "NLTK",
      "ORG"
    ],
    [
      "6",
      "CARDINAL"
    ],
    [
      "Yangyang Liu",
      "PERSON"
    ],
    [
      "Shoubin Li",
      "PERSON"
    ],
    [
      "Loc",
      "PERSON"
    ],
    [
      "2",
      "CARDINAL"
    ],
    [
      "SBERT",
      "ORG"
    ],
    [
      "Fig",
      "PERSON"
    ],
    [
      "2",
      "CARDINAL"
    ],
    [
      "two",
      "CARDINAL"
    ],
    [
      "Subse-",
      "PERSON"
    ],
    [
      "Fig",
      "PERSON"
    ],
    [
      "2",
      "CARDINAL"
    ],
    [
      "6",
      "CARDINAL"
    ],
    [
      "max",
      "PERSON"
    ],
    [
      "max",
      "PERSON"
    ],
    [
      "BERT",
      "ORG"
    ],
    [
      "ω1",
      "CARDINAL"
    ],
    [
      "Title Suppressed Due to Excessive Length",
      "WORK_OF_ART"
    ],
    [
      "7",
      "CARDINAL"
    ],
    [
      "Ek",
      "PERSON"
    ],
    [
      "1",
      "CARDINAL"
    ],
    [
      "∗means",
      "NORP"
    ],
    [
      "the top right half",
      "DATE"
    ],
    [
      "Fig",
      "PERSON"
    ],
    [
      "2",
      "CARDINAL"
    ],
    [
      "N*N",
      "ORG"
    ],
    [
      "N*N",
      "ORG"
    ],
    [
      "three",
      "CARDINAL"
    ],
    [
      "1",
      "CARDINAL"
    ],
    [
      "c(e1",
      "ORG"
    ],
    [
      "6",
      "CARDINAL"
    ],
    [
      "max",
      "PERSON"
    ],
    [
      "2",
      "CARDINAL"
    ],
    [
      "BERT",
      "ORG"
    ],
    [
      "ωe2",
      "PERSON"
    ],
    [
      "c(ωe1",
      "ORG"
    ],
    [
      "ωe2",
      "WORK_OF_ART"
    ],
    [
      "ωe2",
      "WORK_OF_ART"
    ],
    [
      "p(c(ωe1",
      "GPE"
    ],
    [
      "ωe2",
      "PERSON"
    ],
    [
      "3",
      "CARDINAL"
    ],
    [
      "k2",
      "PERSON"
    ],
    [
      "three",
      "CARDINAL"
    ],
    [
      "∗p(ωe1",
      "PERSON"
    ],
    [
      "2",
      "CARDINAL"
    ],
    [
      "∗means",
      "NORP"
    ],
    [
      "8",
      "CARDINAL"
    ],
    [
      "Yangyang Liu",
      "PERSON"
    ],
    [
      "Shoubin Li",
      "PERSON"
    ],
    [
      "two",
      "CARDINAL"
    ],
    [
      "SBERT",
      "ORG"
    ],
    [
      "4.1",
      "CARDINAL"
    ],
    [
      "two",
      "CARDINAL"
    ],
    [
      "one",
      "CARDINAL"
    ],
    [
      "1",
      "CARDINAL"
    ],
    [
      "Conll04",
      "GPE"
    ],
    [
      "9",
      "CARDINAL"
    ],
    [
      "four",
      "CARDINAL"
    ],
    [
      "Kill, Organization-Based-In",
      "ORG"
    ],
    [
      "Located-In",
      "ORG"
    ],
    [
      "10",
      "CARDINAL"
    ],
    [
      "1153",
      "DATE"
    ],
    [
      "288",
      "CARDINAL"
    ],
    [
      "2",
      "CARDINAL"
    ],
    [
      "ADE",
      "ORG"
    ],
    [
      "11",
      "CARDINAL"
    ],
    [
      "Adverse-Eﬀect and Drug",
      "WORK_OF_ART"
    ],
    [
      "Adverse-Eﬀect",
      "WORK_OF_ART"
    ],
    [
      "ten",
      "CARDINAL"
    ],
    [
      "6",
      "CARDINAL"
    ],
    [
      "3",
      "CARDINAL"
    ],
    [
      "PDF",
      "ORG"
    ],
    [
      "2000",
      "CARDINAL"
    ],
    [
      "two",
      "CARDINAL"
    ],
    [
      "DOI",
      "ORG"
    ],
    [
      "Alkali\nSource",
      "ORG"
    ],
    [
      "Crystallization Conditions",
      "ORG"
    ],
    [
      "Crystallization Conditions",
      "ORG"
    ],
    [
      "Gel Composition",
      "ORG"
    ],
    [
      "Silicon Source",
      "ORG"
    ],
    [
      "Aluminum Source",
      "PERSON"
    ],
    [
      "Molecular Sieve Structure Information",
      "WORK_OF_ART"
    ],
    [
      "4.2",
      "CARDINAL"
    ],
    [
      "two",
      "CARDINAL"
    ],
    [
      "SBERT",
      "PERSON"
    ],
    [
      "12",
      "CARDINAL"
    ],
    [
      "13",
      "CARDINAL"
    ],
    [
      "Relation-Metric",
      "ORG"
    ],
    [
      "14",
      "CARDINAL"
    ],
    [
      "Relation-Metric",
      "ORG"
    ],
    [
      "15",
      "CARDINAL"
    ],
    [
      "Spert",
      "ORG"
    ],
    [
      "6",
      "CARDINAL"
    ],
    [
      "Model Conﬁguration: Pre-training",
      "ORG"
    ],
    [
      "BERTBASE",
      "ORG"
    ],
    [
      "English",
      "LANGUAGE"
    ],
    [
      "Learning Rate",
      "PERSON"
    ],
    [
      "0.1",
      "CARDINAL"
    ],
    [
      "Width Embedding",
      "PERSON"
    ],
    [
      "10",
      "CARDINAL"
    ],
    [
      "25",
      "CARDINAL"
    ],
    [
      "Batch Size",
      "PERSON"
    ],
    [
      "Title Suppressed Due to Excessive Length",
      "WORK_OF_ART"
    ],
    [
      "9",
      "CARDINAL"
    ],
    [
      "Relational Filtering",
      "ORG"
    ],
    [
      "30",
      "CARDINAL"
    ],
    [
      "2",
      "CARDINAL"
    ],
    [
      "0.4",
      "CARDINAL"
    ],
    [
      "100",
      "CARDINAL"
    ],
    [
      "6",
      "CARDINAL"
    ],
    [
      "10",
      "CARDINAL"
    ],
    [
      "60",
      "CARDINAL"
    ],
    [
      "Spans",
      "NORP"
    ],
    [
      "zeros",
      "CARDINAL"
    ],
    [
      "F1",
      "ORG"
    ],
    [
      "TP",
      "ORG"
    ],
    [
      "True Positive",
      "ORG"
    ],
    [
      "TN",
      "ORG"
    ],
    [
      "True Negative",
      "ORG"
    ],
    [
      "False Negative",
      "PERSON"
    ],
    [
      "FP",
      "ORG"
    ],
    [
      "False Positive\n",
      "WORK_OF_ART"
    ],
    [
      "3",
      "CARDINAL"
    ],
    [
      "F1",
      "GPE"
    ],
    [
      "2",
      "CARDINAL"
    ],
    [
      "4",
      "CARDINAL"
    ],
    [
      "ten-fold",
      "CARDINAL"
    ],
    [
      "1",
      "CARDINAL"
    ],
    [
      "Speciﬁcally",
      "PERSON"
    ],
    [
      "1%",
      "PERCENT"
    ],
    [
      "Macro F1",
      "ORG"
    ],
    [
      "F1",
      "GPE"
    ],
    [
      "72.87",
      "CARDINAL"
    ],
    [
      "ADE",
      "ORG"
    ],
    [
      "4.3\nResult",
      "QUANTITY"
    ],
    [
      "ADE",
      "ORG"
    ],
    [
      "1",
      "CARDINAL"
    ],
    [
      "ADE",
      "ORG"
    ],
    [
      "10",
      "CARDINAL"
    ],
    [
      "Yangyang Liu",
      "PERSON"
    ],
    [
      "Shoubin Li",
      "PERSON"
    ],
    [
      "1",
      "CARDINAL"
    ],
    [
      "Ten",
      "CARDINAL"
    ],
    [
      "ADE",
      "ORG"
    ],
    [
      "Dataset",
      "ORG"
    ],
    [
      "NER",
      "ORG"
    ],
    [
      "61.95",
      "CARDINAL"
    ],
    [
      "83.60",
      "CARDINAL"
    ],
    [
      "62.04",
      "CARDINAL"
    ],
    [
      "83.90",
      "CARDINAL"
    ],
    [
      "Relation-Metric",
      "ORG"
    ],
    [
      "62.29",
      "CARDINAL"
    ],
    [
      "64.40",
      "CARDINAL"
    ],
    [
      "86.20",
      "CARDINAL"
    ],
    [
      "Spert",
      "ORG"
    ],
    [
      "72.87",
      "CARDINAL"
    ],
    [
      "86.25",
      "CARDINAL"
    ],
    [
      "73.18",
      "CARDINAL"
    ],
    [
      "87.19",
      "CARDINAL"
    ],
    [
      "74.58",
      "CARDINAL"
    ],
    [
      "86.40",
      "CARDINAL"
    ],
    [
      "75.52",
      "CARDINAL"
    ],
    [
      "86.73",
      "CARDINAL"
    ],
    [
      "Relation-Metric",
      "ORG"
    ],
    [
      "77.19",
      "CARDINAL"
    ],
    [
      "87.02",
      "CARDINAL"
    ],
    [
      "78.84",
      "CARDINAL"
    ],
    [
      "89.28",
      "CARDINAL"
    ],
    [
      "Spert",
      "ORG"
    ],
    [
      "79.24",
      "CARDINAL"
    ],
    [
      "89.25",
      "CARDINAL"
    ],
    [
      "79.84",
      "CARDINAL"
    ],
    [
      "89.65",
      "CARDINAL"
    ],
    [
      "4.4",
      "CARDINAL"
    ],
    [
      "SBERT",
      "PERSON"
    ],
    [
      "four",
      "CARDINAL"
    ],
    [
      "Table 2.",
      "PRODUCT"
    ],
    [
      "0.93",
      "CARDINAL"
    ],
    [
      "0.96",
      "CARDINAL"
    ],
    [
      "0.60",
      "CARDINAL"
    ],
    [
      "0.90",
      "CARDINAL"
    ],
    [
      "0.63",
      "CARDINAL"
    ],
    [
      "0.95",
      "CARDINAL"
    ],
    [
      "0.77",
      "CARDINAL"
    ],
    [
      "0.91",
      "CARDINAL"
    ],
    [
      "0.80",
      "CARDINAL"
    ],
    [
      "0.79",
      "CARDINAL"
    ],
    [
      "0.85",
      "CARDINAL"
    ],
    [
      "0.88",
      "CARDINAL"
    ],
    [
      "0.57",
      "CARDINAL"
    ],
    [
      "0.76",
      "CARDINAL"
    ],
    [
      "Silicon Source",
      "FAC"
    ],
    [
      "0.57",
      "CARDINAL"
    ],
    [
      "0.43",
      "CARDINAL"
    ],
    [
      "Molecular Sieve Structure Information",
      "WORK_OF_ART"
    ],
    [
      "0.79",
      "CARDINAL"
    ],
    [
      "1/3",
      "CARDINAL"
    ],
    [
      "2/3",
      "CARDINAL"
    ],
    [
      "1",
      "CARDINAL"
    ],
    [
      "Title Suppressed Due to Excessive Length",
      "WORK_OF_ART"
    ],
    [
      "11",
      "CARDINAL"
    ],
    [
      "ten-fold",
      "CARDINAL"
    ],
    [
      "90%",
      "PERCENT"
    ],
    [
      "69%",
      "PERCENT"
    ],
    [
      "78%",
      "PERCENT"
    ],
    [
      "Table 2",
      "LAW"
    ],
    [
      "SBERT",
      "PERSON"
    ],
    [
      "AutoIE",
      "GPE"
    ],
    [
      "3",
      "CARDINAL"
    ],
    [
      "File\nTradition method Auto method File\nTradition method Auto",
      "ORG"
    ],
    [
      "16min35s",
      "CARDINAL"
    ],
    [
      "13min28s",
      "CARDINAL"
    ],
    [
      "14min07s",
      "CARDINAL"
    ],
    [
      "13min07s",
      "CARDINAL"
    ],
    [
      "52s",
      "CARDINAL"
    ],
    [
      "13min45s",
      "CARDINAL"
    ],
    [
      "17min02s",
      "CARDINAL"
    ],
    [
      "1s",
      "CARDINAL"
    ],
    [
      "23s\nGY-7\n14min50s",
      "QUANTITY"
    ],
    [
      "2min 56s",
      "DATE"
    ],
    [
      "16min28s",
      "CARDINAL"
    ],
    [
      "3",
      "CARDINAL"
    ],
    [
      "third",
      "ORDINAL"
    ],
    [
      "more than three",
      "CARDINAL"
    ],
    [
      "Fig",
      "PERSON"
    ],
    [
      "3",
      "CARDINAL"
    ],
    [
      "5",
      "CARDINAL"
    ],
    [
      "four",
      "CARDINAL"
    ],
    [
      "AFBRSC",
      "ORG"
    ],
    [
      "SBERT",
      "ORG"
    ],
    [
      "12",
      "CARDINAL"
    ],
    [
      "Yangyang Liu",
      "PERSON"
    ],
    [
      "Shoubin Li",
      "PERSON"
    ],
    [
      "2",
      "MONEY"
    ],
    [
      "Belong",
      "GPE"
    ],
    [
      "Belong",
      "GPE"
    ],
    [
      "Belong",
      "GPE"
    ],
    [
      "Belong",
      "GPE"
    ],
    [
      "Belong",
      "GPE"
    ],
    [
      "Belong",
      "GPE"
    ],
    [
      "Belong",
      "GPE"
    ],
    [
      "Belong",
      "GPE"
    ],
    [
      "Belong",
      "GPE"
    ],
    [
      "2",
      "MONEY"
    ],
    [
      "Belong",
      "GPE"
    ],
    [
      "Belong",
      "GPE"
    ],
    [
      "Belong",
      "GPE"
    ],
    [
      "Belong",
      "GPE"
    ],
    [
      "Belong",
      "GPE"
    ],
    [
      "Belong",
      "GPE"
    ],
    [
      "Belong",
      "GPE"
    ],
    [
      "Belong",
      "GPE"
    ],
    [
      "Belong",
      "GPE"
    ],
    [
      "Fig",
      "PERSON"
    ],
    [
      "3",
      "CARDINAL"
    ],
    [
      "AutoIE",
      "GPE"
    ],
    [
      "speciﬁc scientiﬁc contexts",
      "PERSON"
    ],
    [
      "AI",
      "GPE"
    ],
    [
      "1",
      "CARDINAL"
    ],
    [
      "Karen",
      "PERSON"
    ],
    [
      "US Trends and International Comparisons",
      "ORG"
    ],
    [
      "Science & Engineering Indicators",
      "ORG"
    ],
    [
      "2020",
      "DATE"
    ],
    [
      "NSB-2020-6",
      "CARDINAL"
    ],
    [
      "2019",
      "DATE"
    ],
    [
      "2",
      "CARDINAL"
    ],
    [
      "Li",
      "PERSON"
    ],
    [
      "Shoubin",
      "PERSON"
    ],
    [
      "al",
      "PERSON"
    ],
    [
      "18th",
      "ORDINAL"
    ],
    [
      "Paciﬁc Rim",
      "FAC"
    ],
    [
      "Conference on Artiﬁcial Intelligence",
      "ORG"
    ],
    [
      "Hanoi",
      "GPE"
    ],
    [
      "Vietnam",
      "GPE"
    ],
    [
      "November 8–12, 2021",
      "DATE"
    ],
    [
      "18",
      "CARDINAL"
    ],
    [
      "International Publishing",
      "ORG"
    ],
    [
      "2021",
      "DATE"
    ],
    [
      "3",
      "CARDINAL"
    ],
    [
      "Li",
      "PERSON"
    ],
    [
      "Shoubin",
      "PERSON"
    ],
    [
      "Qing Wang",
      "PERSON"
    ],
    [
      "International Journal on Document Analysis",
      "ORG"
    ],
    [
      "Recognition",
      "ORG"
    ],
    [
      "IJDAR",
      "ORG"
    ],
    [
      "24.4",
      "CARDINAL"
    ],
    [
      "2021",
      "DATE"
    ],
    [
      "339",
      "CARDINAL"
    ],
    [
      "4",
      "CARDINAL"
    ],
    [
      "Neumann",
      "ORG"
    ],
    [
      "Mark",
      "PERSON"
    ],
    [
      "al",
      "PERSON"
    ],
    [
      "2019",
      "DATE"
    ],
    [
      "5",
      "CARDINAL"
    ],
    [
      "Lee",
      "PERSON"
    ],
    [
      "Kenton",
      "GPE"
    ],
    [
      "al",
      "PERSON"
    ],
    [
      "2017",
      "DATE"
    ],
    [
      "6",
      "CARDINAL"
    ],
    [
      "Markus",
      "PERSON"
    ],
    [
      "Adrian Ulges",
      "ORG"
    ],
    [
      "2019",
      "DATE"
    ],
    [
      "7",
      "CARDINAL"
    ],
    [
      "A. Rogers",
      "PERSON"
    ],
    [
      "O. Kovaleva",
      "PERSON"
    ],
    [
      "A. Rumshisky",
      "PERSON"
    ],
    [
      "bert works",
      "PERSON"
    ],
    [
      "8",
      "CARDINAL"
    ],
    [
      "pp",
      "GPE"
    ],
    [
      "842–866",
      "CARDINAL"
    ],
    [
      "2020",
      "DATE"
    ],
    [
      "13",
      "CARDINAL"
    ],
    [
      "Loper",
      "PERSON"
    ],
    [
      "Edward",
      "PERSON"
    ],
    [
      "Steven Bird",
      "PERSON"
    ],
    [
      "9",
      "CARDINAL"
    ],
    [
      "Roth",
      "PERSON"
    ],
    [
      "Dan",
      "PERSON"
    ],
    [
      "Wen-tau Yih",
      "PERSON"
    ],
    [
      "eighth",
      "ORDINAL"
    ],
    [
      "HLT-NAACL 2004",
      "ORG"
    ],
    [
      "2004",
      "DATE"
    ],
    [
      "10",
      "CARDINAL"
    ],
    [
      "Gupta",
      "PERSON"
    ],
    [
      "Pankaj",
      "GPE"
    ],
    [
      "Hinrich Schütze",
      "PERSON"
    ],
    [
      "Bernt Andrassy",
      "PERSON"
    ],
    [
      "the 26th International Conference on Computational Linguistics",
      "ORG"
    ],
    [
      "2016",
      "DATE"
    ],
    [
      "11",
      "CARDINAL"
    ],
    [
      "Gurulingappa",
      "PERSON"
    ],
    [
      "Harsha",
      "PERSON"
    ],
    [
      "al",
      "PERSON"
    ],
    [
      "Journal",
      "ORG"
    ],
    [
      "45.5",
      "CARDINAL"
    ],
    [
      "2012",
      "DATE"
    ],
    [
      "885",
      "CARDINAL"
    ],
    [
      "12",
      "CARDINAL"
    ],
    [
      "Giannis",
      "PERSON"
    ],
    [
      "al",
      "PERSON"
    ],
    [
      "2018",
      "DATE"
    ],
    [
      "13",
      "CARDINAL"
    ],
    [
      "Giannis",
      "PERSON"
    ],
    [
      "al",
      "PERSON"
    ],
    [
      "114",
      "CARDINAL"
    ],
    [
      "2018",
      "DATE"
    ],
    [
      "34-45",
      "DATE"
    ],
    [
      "14",
      "CARDINAL"
    ],
    [
      "Tran",
      "PERSON"
    ],
    [
      "Tung",
      "PERSON"
    ],
    [
      "Ramakanth Kavuluru",
      "LOC"
    ],
    [
      "2019",
      "DATE"
    ],
    [
      "15",
      "CARDINAL"
    ],
    [
      "Nguyen",
      "PERSON"
    ],
    [
      "Karin Verspoor",
      "ORG"
    ],
    [
      "41st European\nConference on IR Research",
      "ORG"
    ],
    [
      "2019",
      "DATE"
    ],
    [
      "Cologne",
      "GPE"
    ],
    [
      "Germany",
      "GPE"
    ],
    [
      "April 14–18, 2019",
      "DATE"
    ],
    [
      "41",
      "CARDINAL"
    ],
    [
      "International Publishing",
      "ORG"
    ],
    [
      "2019",
      "DATE"
    ],
    [
      "16",
      "CARDINAL"
    ],
    [
      "Dai",
      "PERSON"
    ],
    [
      "Jifeng",
      "PERSON"
    ],
    [
      "al",
      "PERSON"
    ],
    [
      "29",
      "CARDINAL"
    ],
    [
      "2016",
      "DATE"
    ],
    [
      "17",
      "CARDINAL"
    ],
    [
      "Liu",
      "PERSON"
    ],
    [
      "Wei",
      "PERSON"
    ],
    [
      "al",
      "PERSON"
    ],
    [
      "2016",
      "CARDINAL"
    ],
    [
      "14th",
      "ORDINAL"
    ],
    [
      "European Conference",
      "ORG"
    ],
    [
      "Amsterdam",
      "GPE"
    ],
    [
      "The Netherlands",
      "GPE"
    ],
    [
      "October 11–14",
      "DATE"
    ],
    [
      "2016",
      "DATE"
    ],
    [
      "14",
      "CARDINAL"
    ],
    [
      "International Publishing",
      "ORG"
    ],
    [
      "2016",
      "DATE"
    ],
    [
      "18",
      "CARDINAL"
    ],
    [
      "Redmon",
      "PERSON"
    ],
    [
      "Joseph",
      "PERSON"
    ],
    [
      "Ali Farhadi",
      "PERSON"
    ],
    [
      "IEEE",
      "ORG"
    ],
    [
      "2017",
      "DATE"
    ],
    [
      "19",
      "CARDINAL"
    ],
    [
      "2017 14th",
      "DATE"
    ],
    [
      "IAPR International Conference on Document Analysis",
      "EVENT"
    ],
    [
      "Recognition",
      "ORG"
    ],
    [
      "2017",
      "DATE"
    ],
    [
      "776",
      "CARDINAL"
    ],
    [
      "20",
      "CARDINAL"
    ],
    [
      "Saman",
      "ORG"
    ],
    [
      "Faisal Shafait",
      "PERSON"
    ],
    [
      "2018",
      "DATE"
    ],
    [
      "Digital Image Computing: Techniques",
      "ORG"
    ],
    [
      "IEEE",
      "ORG"
    ],
    [
      "2018",
      "DATE"
    ],
    [
      "21",
      "CARDINAL"
    ],
    [
      "Yu",
      "PERSON"
    ],
    [
      "Bowen",
      "PERSON"
    ],
    [
      "al",
      "PERSON"
    ],
    [
      "2019",
      "DATE"
    ],
    [
      "22",
      "CARDINAL"
    ],
    [
      "Zeng",
      "PERSON"
    ],
    [
      "Xiangrong",
      "GPE"
    ],
    [
      "al",
      "PERSON"
    ],
    [
      "56th",
      "ORDINAL"
    ],
    [
      "Association",
      "ORG"
    ],
    [
      "Computational Linguistics (",
      "ORG"
    ],
    [
      "1",
      "CARDINAL"
    ],
    [
      "2018",
      "DATE"
    ],
    [
      "23",
      "CARDINAL"
    ],
    [
      "Huang",
      "PERSON"
    ],
    [
      "Weipeng",
      "PERSON"
    ],
    [
      "al",
      "PERSON"
    ],
    [
      "Bert-",
      "PERSON"
    ],
    [
      "Natural Language Processing and Chinese Computing",
      "WORK_OF_ART"
    ],
    [
      "8th",
      "ORDINAL"
    ],
    [
      "2019",
      "DATE"
    ],
    [
      "Dunhuang",
      "GPE"
    ],
    [
      "China",
      "GPE"
    ],
    [
      "October",
      "DATE"
    ],
    [
      "2019",
      "DATE"
    ],
    [
      "II 8",
      "DATE"
    ],
    [
      "International Publishing",
      "ORG"
    ],
    [
      "2019",
      "DATE"
    ],
    [
      "24",
      "CARDINAL"
    ],
    [
      "Hasan",
      "PERSON"
    ],
    [
      "Fatema",
      "PERSON"
    ],
    [
      "Arpita Roy",
      "PERSON"
    ],
    [
      "Shimei Pan",
      "PERSON"
    ],
    [
      "NLP",
      "ORG"
    ],
    [
      "2020",
      "DATE"
    ],
    [
      "IEEE",
      "ORG"
    ],
    [
      "2020",
      "DATE"
    ]
  ],
  "sections": {
    "abstract": "Abstract. In the rapidly evolving ﬁeld of scientiﬁc research, eﬃciently\nextracting key information from the burgeoning volume of scientiﬁc pa-\npers remains a formidable challenge. This paper introduces an innovative\nframework designed to automate the extraction of vital data from scien-\ntiﬁc PDF documents, enabling researchers to discern future research tra-\njectories more readily. AutoIE uniquely integrates four novel components:\n(1) A multi-semantic feature fusion-based approach for PDF document\nlayout analysis; (2) Advanced functional block recognition in scientiﬁc\ntexts; (3) A synergistic technique for extracting and correlating infor-\nmation on molecular sieve synthesis; (4) An online learning paradigm\ntailored for molecular sieve literature. Our SBERT model achieves high\nMarco F1 scores of 87.19 and 89.65 on CoNLL04 and ADE datasets. In\naddition, a practical application of AutoIE in the petrochemical molec-\nular sieve synthesis domain demonstrates its eﬃcacy, evidenced by an\nimpressive 78% accuracy rate. This research paves the way for enhanced\ndata management and interpretation in molecular sieve synthesis. It is\na valuable asset for seasoned experts and newcomers in this specialized\nﬁeld.\nKeywords: Information Extraction · Layout Analysis · scientiﬁc docu-\nment Analysis.\n1",
    "introduction": "Introduction\nRecent statistics reveal a general trend of an approximate 4% annual increase in\nthe publication rate of scientiﬁc and technological papers, signifying the rapid\nadvancement and dynamic nature of contemporary research [1]. The burgeoning\nvolume of scientiﬁc literature precipitates a critical challenge: the urgent need\nfor eﬃcient and precise automated information extraction technologies. Tradi-\ntional methods, once reliable, now struggle to cope with data’s expanding scale\nand complexity, rendering them increasingly ineﬀective. Our study proposes an\ninnovative framework, AutoIE, for rapidly and accurately extracting essential\ninformation from scientiﬁc texts.\nWe identify several key obstacles in developing a robust framework for this\npurpose:\n2\nYangyang Liu and Shoubin Li\n– (1) Length and Complexity: The length of scientiﬁc and technological\npapers is very long, and it is diﬃcult to quickly locate and mine the valu-\nable information in the text in such a long length. For example, to extract\nthe comparative",
    "methodology": "methodology allows for retaining relative positional information within the span,\nadding a syntactic layer to our analysis.\n3.2.2 Model Architecture\nOur model’s architecture (shown in Fig. 2) is tailored for scientiﬁc text anal-\nysis. It encompasses two principal components: span classiﬁcation and relational\nanalysis. Initially, the model classiﬁes spans to pinpoint key entities. Subse-\nquently, it examines the relationships between these entities, contextualizing\nthem within the broader scientiﬁc discourse.\nSpan classiﬁcation: The internal architecture of this stage is shown in\nthe lower right half of Fig. 2. The input is a span composed of tokens, and\nthe output is the entity tag of the span. The number of entity tags is k+1\n(the predeﬁned k entity types plus one none type). Span vector is represented\nby S = (t1, t2, ..., tn). This part is transformed into f(t1, t2, ..., tn). after max-\npooling function. In [6], it is veriﬁed through experiments that max-pooling is\nmore eﬀective than other pooling operations regarding text feature representa-\ntion. Therefore, we also use the max-pooling method to extract the maximum\nfeature of the span vector. The span before BERT encoding is the original text,\nrepresented by W = (ω1, ω2, ..., ωn). After each token in the span is converted\ninto part of speech, the part of speech vector p(ω1, ω2, ..., ωn) can be obtained by\nbinary coding. To ﬁlter entities whose span length is too long, we add the width\nfeature of the span. The length of the input span is k, and the width embedding\nTitle Suppressed Due to Excessive Length\n7\nobtained after looking up the word embedding table is Ek. Therefore, what is\nﬁnally entered in the span classiﬁer is:\nxs = f(t1, t2, ..., tn) ∗p(ω1, ω2, ..., ωn) ∗Ek ∗c\n(1)\nWhere c means CLS classiﬁcation mark, and ∗means vector splicing. The\nspliced vector passes through the softmax classiﬁer, and each span is labelled\nwith an entity label (including the none label).\nRelation classiﬁcation: The internal architecture of this stage is shown\nin the top right half of Fig. 2. After screening the spans classiﬁed as none, N\nspan entities remain. The generated candidate entity pairs have N*N groups.\nThe model’s input is N*N entity pairs, and the output is the relationship label\nof each entity pair. The characteristics of each entity pair input to the relational\nclassiﬁer are composed of three categories:\n– 1) Let (e1, e2) denote the input entity pair vector, and c(e1, e2) denote the\ntext encoding between the entity pairs. According to experiments [6], it is\nproved that the text between entities is compared with the whole sentence\nand CLS label. Regarding the relationship classiﬁcation eﬀect, the text be-\ntween entity pairs performs best. Therefore, we use the text between entity\npairs as the relation classiﬁcation feature. The entity pair and the text pass\nthrough the max-pooling layer respectively, and the generated vectors are\nrepresented as f(e1, e2) and f(c(e1, e2)).\n– 2) Considering the importance of the part-of-speech order at the junction\nbetween the head and tail entities and the text, the entity and the text\nare transformed into part-of-speech features. The entity pair before BERT\nencoding is represented as (ωe1, ωe2), and the text between entity pairs is rep-\nresented as c(ωe1, ωe2). After being converted into a part-of-speech sequence,\nit is encoded in binary. Entity pair and text correspond to p(ωe1, ωe2) and\np(c(ωe1, ωe2)) respectively. After adding part-of-speech features, the model\ncan ﬁlter out entity pairs that do not conform to the regular part-of-speech\norder in relation extraction.\n– 3) The width embedding of entity pairs is also used as a feature of relation\nclassiﬁcation. The length of the token of the input entity pair is expressed\nas (k1, k2), and the converted width embedding is expressed as W(ωe1, ωe2).\nThe three types of feature vectors are spliced and input into the relational\nclassiﬁer. The spliced vector is expressed as follows:\nxr = f(e1, e2) ∗f(c(e1, e2)) ∗p(ωe1, ωe2) ∗p(c(ωe1, ωe2)) ∗(Ek1, Ek2)\n(2)\nWhere ∗means vector splicing. The spliced vector is input to the single-layer\nclassiﬁer and activated by the sigmoid function. The relationship label with the\nhighest score in the sigmoid layer is taken as the relationship between the entity\npairs. At the same time, the threshold is set, and the sigmoid function can only\nbe activated if it is greater than the threshold. Otherwise, there is no relationship\nbetween the entities.\n8\nYangyang Liu and Shoubin Li\n4\nExperiment\nThis section describes data, experiments, and evaluations of our",
    "results": "results of various experimental methods in scientiﬁc and\ntechnological papers, it is only necessary to extract the \"experimental re-\nsults\" chapter of the paper. In this process, a large amount of text and data\ninformation in other chapters are noise data;\n– (2) Limitations of Current Information Extraction Methods: The\ncurrent information extraction methods have achieved good",
    "conclusion": "Conclusion\nIn this research, we developed an innovative framework for extracting key infor-\nmation from scientiﬁc papers, encompassing four main components: MFFAPD,\nAFBRSC, STECIM, and OLPTMS. This framework is further augmented by\nintroducing a relational entity joint extraction algorithm, SBERT, based on\nSpERT. Applying this comprehensive framework in molecular sieve synthesis\nliterature has demonstrated its eﬀectiveness, showcasing the potential of our\napproach in facilitating advanced information extraction. In the future, our re-\nsearch will explore integrating general-purpose large language models, such as\nChatGPT, into our existing framework. This integration aims to enhance the\n12\nYangyang Liu and Shoubin Li\nSilicon \nSource #1\nSilicon \nSource #1\nGermanium \nSource #1\nFluorine \nSource #1\nGel \nComposition\nGermanium \nSource #2\nFluorine \nSource #2\nCrystallization \nCondition \nTemperature #1\nCrystallization \nCondition Time # 1\nCrystallization \nCondition Time # 2\nTemplate\nBelong to\nBelong to\nBelong to\nBelong to\nBelong to\nBelong to\nBelong to\nBelong to\nBelong to\nBelong to\nSilicon \nSource #1\nSilicon \nSource #1\nGermanium \nSource #1\nFluorine \nSource #1\nGel \nComposition\nGermanium \nSource #2\nFluorine \nSource #2\nCrystallization \nCondition \nTemperature #1\nCrystallization \nCondition Time # 1\nCrystallization \nCondition Time # 2\nTemplate\nBelong to\nBelong to\nBelong to\nBelong to\nBelong to\nBelong to\nBelong to\nBelong to\nBelong to\nBelong to\nFig. 3. The display exhibits the outcomes from AutoIE. Situated on the left-hand side\nof the ﬁgure, one can observe an array of prevalent labels pertinent to the synthesis\nof molecular sieves, including but not limited to, ’Author’, ’Title’, ’Unit’, and ’Silicon\nSource’.\naccuracy and eﬃciency of key information extraction, particularly in domain-\nspeciﬁc scientiﬁc contexts. Our objective is to leverage the evolving capabilities\nof AI and machine learning to reﬁne and expand the scope of automated infor-\nmation extraction in specialized scientiﬁc ﬁelds.\nReferences\n1. White, Karen. \"Publications Output: US Trends and International Comparisons.\nScience & Engineering Indicators 2020. NSB-2020-6.\" National Science Foundation\n(2019).\n2. Li, Shoubin, et al. \"Vtlayout: Fusion of visual and text features for document lay-\nout analysis.\" PRICAI 2021: Trends in Artiﬁcial Intelligence: 18th Paciﬁc Rim In-\nternational Conference on Artiﬁcial Intelligence, PRICAI 2021, Hanoi, Vietnam,\nNovember 8–12, 2021, Proceedings, Part I 18. Springer International Publishing,\n2021.\n3. Li, Shoubin, and Qing Wang. \"A hybrid approach to recognize generic sections in\nscholarly documents.\" International Journal on Document Analysis and Recognition\n(IJDAR) 24.4 (2021): 339-348.\n4. Neumann, Mark, et al. \"ScispaCy: fast and robust models for biomedical natural\nlanguage processing.\" arXiv preprint arXiv:1902.07669 (2019).\n5. Lee, Kenton, et al. \"End-to-end neural coreference resolution.\" arXiv preprint\narXiv:1707.07045 (2017).\n6. Eberts, Markus, and Adrian Ulges. \"Span-based joint entity and relation extraction\nwith transformer pre-training.\" arXiv preprint arXiv:1909.07755 (2019).\n7. A. Rogers, O. Kovaleva, and A. Rumshisky, “A primer in bertology: What we know\nabout how bert works,” Transactions of the Association for Computational Linguis-\ntics, vol. 8, pp. 842–866, 2020.\nTitle Suppressed Due to Excessive Length\n13\n8. Loper, Edward, and Steven Bird. \"Nltk: The natural language toolkit.\" arXiv\npreprint cs/0205028 (2002).\n9. Roth, Dan, and Wen-tau Yih. \"A linear programming formulation for global infer-\nence in natural language tasks.\" Proceedings of the eighth conference on computa-\ntional natural language learning (CoNLL-2004) at HLT-NAACL 2004. 2004.\n10. Gupta, Pankaj, Hinrich Schütze, and Bernt Andrassy. \"Table ﬁlling multi-task\nrecurrent neural network for joint entity and relation extraction.\" Proceedings of\nCOLING 2016, the 26th International Conference on Computational Linguistics:\nTechnical Papers. 2016.\n11. Gurulingappa, Harsha, et al. \"Development of a benchmark corpus to support\nthe automatic extraction of drug-related adverse eﬀects from medical case reports.\"\nJournal of biomedical informatics 45.5 (2012): 885-892.\n12. Bekoulis, Giannis, et al. \"Adversarial training for multi-context joint entity and\nrelation extraction.\" arXiv preprint arXiv:1808.06876 (2018).\n13. Bekoulis, Giannis, et al. \"Joint entity recognition and relation extraction as a multi-\nhead selection problem.\" Expert Systems with Applications 114 (2018): 34-45.\n14. Tran, Tung, and Ramakanth Kavuluru. \"Neural metric learning for fast end-to-end\nrelation extraction.\" arXiv preprint arXiv:1905.07458 (2019).\n15. Nguyen, Dat Quoc, and Karin Verspoor. \"End-to-end neural relation extraction\nusing deep biaﬃne attention.\" Advances in Information Retrieval: 41st European\nConference on IR Research, ECIR 2019, Cologne, Germany, April 14–18, 2019, Pro-\nceedings, Part I 41. Springer International Publishing, 2019.\n16. Dai, Jifeng, et al. \"R-fcn: Object detection via region-based fully convolutional\nnetworks.\" Advances in neural information processing systems 29 (2016).\n17. Liu, Wei, et al. \"Ssd: Single shot multibox detector.\" Computer Vision–ECCV\n2016: 14th European Conference, Amsterdam, The Netherlands, October 11–14,\n2016, Proceedings, Part I 14. Springer International Publishing, 2016.\n18. Redmon, Joseph, and Ali Farhadi. \"YOLO9000: better, faster, stronger.\" Proceed-\nings of the IEEE conference on computer vision and pattern recognition. 2017.\n19. GILANI A, QASIM S R, MALIK M I, et al. Table detection using deep learning[J].\n2017 14th IAPR International Conference on Document Analysis and Recognition\n(ICDAR), 2017, 01:771-776.\n20. Arif, Saman, and Faisal Shafait. \"Table detection in document images using fore-\nground and background features.\" 2018 Digital Image Computing: Techniques and\nApplications (DICTA). IEEE, 2018.\n21. Yu, Bowen, et al. \"Joint extraction of entities and relations based on a novel\ndecomposition strategy.\" arXiv preprint arXiv:1909.04273 (2019).\n22. Zeng, Xiangrong, et al. \"Extracting relational facts by an end-to-end neural model\nwith copy mechanism.\" Proceedings of the 56th Annual Meeting of the Association\nfor Computational Linguistics (Volume 1: Long Papers). 2018.\n23. Huang, Weipeng, et al. \"Bert-based multi-head selection for joint entity-relation\nextraction.\" Natural Language Processing and Chinese Computing: 8th CCF In-\nternational Conference, NLPCC 2019, Dunhuang, China, October 9–14, 2019, Pro-\nceedings, Part II 8. Springer International Publishing, 2019.\n24. Hasan, Fatema, Arpita Roy, and Shimei Pan. \"Integrating text embedding with\ntraditional NLP features for clinical relation extraction.\" 2020 IEEE 32nd Interna-\ntional Conference on Tools with Artiﬁcial Intelligence (ICTAI). IEEE, 2020."
  },
  "core_terms": [
    "entity",
    "extraction",
    "information",
    "model",
    "span",
    "scientiﬁc",
    "framework",
    "relation",
    "source",
    "data"
  ]
}